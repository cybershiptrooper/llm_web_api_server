{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain import HuggingFacePipeline, PromptTemplate, LLMChain\n",
    "from langchain.llms import OpenAI, AzureOpenAI\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils.chain_utils import *\n",
    "# abs path of ../\n",
    "dir = os.path.abspath(\"../\")\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"b11e8b01c8b44b9db9482f8cd7b410d4\"\n",
    "os.environ[\"OPENAI_API_VERSION\"]=\"2023-03-15-preview\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_str = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "        template=prompt_template_str, input_variables=[\"context\", \"prompt\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name=\"text-davinci-003\", max_tokens=3450, temperature=0.0)\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing database tool\n",
      "name='custom_search' description='Useful for when you need to answer questions about the documents given. The result will be exerpts from the documents which you will need to process further.' args_schema=None return_direct=False verbose=False callbacks=None callback_manager=None handle_tool_error=False pdf_paths=['/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf'] texts=[Document(lc_kwargs={'page_content': 'cs 781 project report verifying l1 adverserial robustness rohan gupta 180010048 @ iitb. ac. in mohammad taufeeque 180050062 @ iitb. ac. in abstract. we study the performance of popular neural network verification tools on l1 perturbations. since feeding l1 constraints to solver is exponential in the order of inputs, we experiment with function approximators to possibly reduce the complexity. we give our results on two tools, marabou ( reluplex ) and eran ( deeppoly ) respectively. keywords : verification of neural nets · l1 attack 1 introduction most verification tools show strong experimental results only for l∞ perturbations. however, attacks under other lp norms are becoming increasingly popular. it has also been observed that models robust to l∞ are vulnerable to even small, perceptually minor departures from this family, such as small rotations and trans - lations. therefore, there is a need to look for high performance under other perturbations. the main issue with l∞ perturbations lies in making the bounds larger. since the pixel - wise perturbations are independent, it can easily cross the decision boundaries. [ 2 ] is an example of such adversaries, whose l∞ norm is large, but other lp norms are not. we evaluate the performance of extant tools on l1 perturbations, with some modifications : instead of giving exponential number of equations to the solver, an auxilliary network is used to find the l1 norm ( conditions are then applied to this output ). we also observe some key differences between l1 and l∞ perturbations via our experiments. we show : • over approximations of deeppoly [ 3 ] result in poor performance in the case of l1 norms, and in our formulation,', 'metadata': {'source': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'file_path': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'page': 0, 'total_pages': 4, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.23', 'creationDate': 'D:20230425114654Z', 'modDate': 'D:20230425114654Z', 'trapped': ''}}, page_content='cs 781 project report verifying l1 adverserial robustness rohan gupta 180010048 @ iitb. ac. in mohammad taufeeque 180050062 @ iitb. ac. in abstract. we study the performance of popular neural network verification tools on l1 perturbations. since feeding l1 constraints to solver is exponential in the order of inputs, we experiment with function approximators to possibly reduce the complexity. we give our results on two tools, marabou ( reluplex ) and eran ( deeppoly ) respectively. keywords : verification of neural nets · l1 attack 1 introduction most verification tools show strong experimental results only for l∞ perturbations. however, attacks under other lp norms are becoming increasingly popular. it has also been observed that models robust to l∞ are vulnerable to even small, perceptually minor departures from this family, such as small rotations and trans - lations. therefore, there is a need to look for high performance under other perturbations. the main issue with l∞ perturbations lies in making the bounds larger. since the pixel - wise perturbations are independent, it can easily cross the decision boundaries. [ 2 ] is an example of such adversaries, whose l∞ norm is large, but other lp norms are not. we evaluate the performance of extant tools on l1 perturbations, with some modifications : instead of giving exponential number of equations to the solver, an auxilliary network is used to find the l1 norm ( conditions are then applied to this output ). we also observe some key differences between l1 and l∞ perturbations via our experiments. we show : • over approximations of deeppoly [ 3 ] result in poor performance in the case of l1 norms, and in our formulation,', metadata={'source': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'file_path': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'page': 0, 'total_pages': 4, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.23', 'creationDate': 'D:20230425114654Z', 'modDate': 'D:20230425114654Z', 'trapped': ''}), Document(lc_kwargs={'page_content': 'also observe some key differences between l1 and l∞ perturbations via our experiments. we show : • over approximations of deeppoly [ 3 ] result in poor performance in the case of l1 norms, and in our formulation, approximates it to it ’ s minimal l∞ super - set space. • strong l∞ perturbations limited to only a small region often leads to misclassification. • a way to reduce large l∞ perturbation regions so that it does not tip over the decision boundaries and a way to reduce spurious counterexamples for high l1 norms. 2 implementation details 2. 1 abstraction based solver ( deeppoly ) deeppoly uses an over - approximation by choosing only two bounding lines to represent the abstraction. if l1 norm constraints were enforced on the input, the exact approximation would require an exponential number of constraints. the over approximation is very bad in this case. figure 1 show the over approximation for a 2 - pixel toy example. we therefore use an independent mlp network to output the l1 norm and apply the needed constraints inside it. the l∞ bounds for the input can then be chosen to be a super set of our original l1 constraints. figure 2 shows a network calculating the l1 norm for a single pixel. we can extend 1', 'metadata': {'source': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'file_path': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'page': 0, 'total_pages': 4, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.23', 'creationDate': 'D:20230425114654Z', 'modDate': 'D:20230425114654Z', 'trapped': ''}}, page_content='also observe some key differences between l1 and l∞ perturbations via our experiments. we show : • over approximations of deeppoly [ 3 ] result in poor performance in the case of l1 norms, and in our formulation, approximates it to it ’ s minimal l∞ super - set space. • strong l∞ perturbations limited to only a small region often leads to misclassification. • a way to reduce large l∞ perturbation regions so that it does not tip over the decision boundaries and a way to reduce spurious counterexamples for high l1 norms. 2 implementation details 2. 1 abstraction based solver ( deeppoly ) deeppoly uses an over - approximation by choosing only two bounding lines to represent the abstraction. if l1 norm constraints were enforced on the input, the exact approximation would require an exponential number of constraints. the over approximation is very bad in this case. figure 1 show the over approximation for a 2 - pixel toy example. we therefore use an independent mlp network to output the l1 norm and apply the needed constraints inside it. the l∞ bounds for the input can then be chosen to be a super set of our original l1 constraints. figure 2 shows a network calculating the l1 norm for a single pixel. we can extend 1', metadata={'source': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'file_path': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'page': 0, 'total_pages': 4, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.23', 'creationDate': 'D:20230425114654Z', 'modDate': 'D:20230425114654Z', 'trapped': ''}), Document(lc_kwargs={'page_content': 'this to multiple pixels by creating two neurons for each pixel pair in the first layer, and adding them in the final layer to get i | pi |. we denote these weights by { ( w i norm, bi norm ), i ∈ { 1, 2 } } figure 1 : l1 norm approximation for a 2 - pixel case figure 2 : l1 norm for a single pixel trained network since the libraries did not support operations like concatenations, tensor splicing and multiple inputs / outputs, we could not use independent networks for verification. we therefore make a sparse mlp network with mul - tiple functionalities, with weights : w i n = w ( w i mnist, w i norm ) = w i norm 000 000 w i mnist ( 1 ) bi n = b ( bi mnist, bi norm ) = bi binorm mnist ( 2 ) given the trained weights { ( w i mnist, bi mnist ), i ∈ { 1, 2, 3 } }. the network then gives an 11 - dimensional vector ( l1, c0, c1.. c9 ), where ci are the class probabilities of the mnist image and l1 is the l1 norm. the neural network used had two linear - relu layers of 100 neurons each and a final layer mapping to the 10 classes with a softmax. since our auxilliary network has 2 layers we add an additional identity layer to it : w 3 norm = 1, bsnorm = 0. the final network verified was on the logits as the network in figure 2 cannot have an a softmax operation. note that this is extendable to any mlp with the appropriate number of identity layers added. encoding the condition for a given l1 bound b0, the condition to verify within an l∞ region becomes ( l1 ≤ b0 ) =', 'metadata': {'source': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'file_path': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'page': 1, 'total_pages': 4, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.23', 'creationDate': 'D:20230425114654Z', 'modDate': 'D:20230425114654Z', 'trapped': ''}}, page_content='this to multiple pixels by creating two neurons for each pixel pair in the first layer, and adding them in the final layer to get i | pi |. we denote these weights by { ( w i norm, bi norm ), i ∈ { 1, 2 } } figure 1 : l1 norm approximation for a 2 - pixel case figure 2 : l1 norm for a single pixel trained network since the libraries did not support operations like concatenations, tensor splicing and multiple inputs / outputs, we could not use independent networks for verification. we therefore make a sparse mlp network with mul - tiple functionalities, with weights : w i n = w ( w i mnist, w i norm ) = w i norm 000 000 w i mnist ( 1 ) bi n = b ( bi mnist, bi norm ) = bi binorm mnist ( 2 ) given the trained weights { ( w i mnist, bi mnist ), i ∈ { 1, 2, 3 } }. the network then gives an 11 - dimensional vector ( l1, c0, c1.. c9 ), where ci are the class probabilities of the mnist image and l1 is the l1 norm. the neural network used had two linear - relu layers of 100 neurons each and a final layer mapping to the 10 classes with a softmax. since our auxilliary network has 2 layers we add an additional identity layer to it : w 3 norm = 1, bsnorm = 0. the final network verified was on the logits as the network in figure 2 cannot have an a softmax operation. note that this is extendable to any mlp with the appropriate number of identity layers added. encoding the condition for a given l1 bound b0, the condition to verify within an l∞ region becomes ( l1 ≤ b0 ) =', metadata={'source': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'file_path': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'page': 1, 'total_pages': 4, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.23', 'creationDate': 'D:20230425114654Z', 'modDate': 'D:20230425114654Z', 'trapped': ''}), Document(lc_kwargs={'page_content': '. note that this is extendable to any mlp with the appropriate number of identity layers added. encoding the condition for a given l1 bound b0, the condition to verify within an l∞ region becomes ( l1 ≤ b0 ) = ⇒ ( ymax = ylabel ) ( 3 ) [UNK] ¬ ( l1 ≤ b0 ) ∨ ( ymax = ylabel ) ( 4 ) [UNK] ( l1 > b0 ) ∨ ( ymax = ylabel ) ( 5 ) the condition l1 > b0 is encoded by checking the lower bound of the output l1 ’ s abstraction. note that, however, it can easily be verified that the lower bound for l1 in our network is just 0. therefore ( ymax = ylabel ) must hold for the entire abstraction for the above condition to hold. approximations in deeppoly reduces the problem to checking l∞ perturbations itself. hence, the over - we observe this phenomenon in our experiments as well. 2. 2 exact solver ( reluplex ) an exact solver [ 1 ] will not make approximation and hence we can directly feed the l1 constraints to the solver. however, feeding l1 norm constraints would need 2pixels equations is not practically feasible. we observe that a region with mere 16 pixels causes memory issues on a standard computer. using and auxilliary 2', 'metadata': {'source': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'file_path': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'page': 1, 'total_pages': 4, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.23', 'creationDate': 'D:20230425114654Z', 'modDate': 'D:20230425114654Z', 'trapped': ''}}, page_content='. note that this is extendable to any mlp with the appropriate number of identity layers added. encoding the condition for a given l1 bound b0, the condition to verify within an l∞ region becomes ( l1 ≤ b0 ) = ⇒ ( ymax = ylabel ) ( 3 ) [UNK] ¬ ( l1 ≤ b0 ) ∨ ( ymax = ylabel ) ( 4 ) [UNK] ( l1 > b0 ) ∨ ( ymax = ylabel ) ( 5 ) the condition l1 > b0 is encoded by checking the lower bound of the output l1 ’ s abstraction. note that, however, it can easily be verified that the lower bound for l1 in our network is just 0. therefore ( ymax = ylabel ) must hold for the entire abstraction for the above condition to hold. approximations in deeppoly reduces the problem to checking l∞ perturbations itself. hence, the over - we observe this phenomenon in our experiments as well. 2. 2 exact solver ( reluplex ) an exact solver [ 1 ] will not make approximation and hence we can directly feed the l1 constraints to the solver. however, feeding l1 norm constraints would need 2pixels equations is not practically feasible. we observe that a region with mere 16 pixels causes memory issues on a standard computer. using and auxilliary 2', metadata={'source': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'file_path': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'page': 1, 'total_pages': 4, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.23', 'creationDate': 'D:20230425114654Z', 'modDate': 'D:20230425114654Z', 'trapped': ''}), Document(lc_kwargs={'page_content': 'l1 result l1 * stddev 0 unsat 0 2 unsat 0. 6 10 unsat 3 20 unsat 6 30 sat 9 table 1 : robustness results for different lc. l∞ norm was fixed at 0. 2 network hence will help us bypass these issues. we perform experiments on both approaches, feeding l1 constraints and using an auxilliary network. we limit to 12 - pixel regions for the former, however. the auxilliary network used is same as the one defined in the above section. encoding the condition reluplex uses hoare triples. the condition 5 hence will be negated, and the network is verified only if ( l1 ≤ b0 ) ∧ ( ymax = ylabel ) gives unsat. 3 experiments and results 3. 1 deeppoly we pass 50 different mnist images through our implementation with various l∞ perturbations. the network with l1 norm constraint behaves exactly like the network without l1 norm constraint. on further analysis, we found that deeppoly uses the lower bound on l1 to check if it is greater than the provided bound. however, since the lower bound of l1 on all the inputs is 0, the condition never gets satisfied and thus the implementation always ends up verifying the output constraint on the whole l∞ input space rather than the constrained l1 input space. we explored different options with deeppoly like the – complete argument, – domain argument with domains like deepzono and deeppoly, but none of the options gave a different result. moreover, we tried to see whether we could use trace partitioning on our input space with deeppoly but found that the option for trace partitioning only exists for two specific cases : 1 ) geometric transformation on an image, and 2 ) on the acasxu dataset. on a higher dimensional space like images, trace', 'metadata': {'source': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'file_path': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'page': 2, 'total_pages': 4, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.23', 'creationDate': 'D:20230425114654Z', 'modDate': 'D:20230425114654Z', 'trapped': ''}}, page_content='l1 result l1 * stddev 0 unsat 0 2 unsat 0. 6 10 unsat 3 20 unsat 6 30 sat 9 table 1 : robustness results for different lc. l∞ norm was fixed at 0. 2 network hence will help us bypass these issues. we perform experiments on both approaches, feeding l1 constraints and using an auxilliary network. we limit to 12 - pixel regions for the former, however. the auxilliary network used is same as the one defined in the above section. encoding the condition reluplex uses hoare triples. the condition 5 hence will be negated, and the network is verified only if ( l1 ≤ b0 ) ∧ ( ymax = ylabel ) gives unsat. 3 experiments and results 3. 1 deeppoly we pass 50 different mnist images through our implementation with various l∞ perturbations. the network with l1 norm constraint behaves exactly like the network without l1 norm constraint. on further analysis, we found that deeppoly uses the lower bound on l1 to check if it is greater than the provided bound. however, since the lower bound of l1 on all the inputs is 0, the condition never gets satisfied and thus the implementation always ends up verifying the output constraint on the whole l∞ input space rather than the constrained l1 input space. we explored different options with deeppoly like the – complete argument, – domain argument with domains like deepzono and deeppoly, but none of the options gave a different result. moreover, we tried to see whether we could use trace partitioning on our input space with deeppoly but found that the option for trace partitioning only exists for two specific cases : 1 ) geometric transformation on an image, and 2 ) on the acasxu dataset. on a higher dimensional space like images, trace', metadata={'source': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'file_path': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'page': 2, 'total_pages': 4, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.23', 'creationDate': 'D:20230425114654Z', 'modDate': 'D:20230425114654Z', 'trapped': ''}), Document(lc_kwargs={'page_content': 'space with deeppoly but found that the option for trace partitioning only exists for two specific cases : 1 ) geometric transformation on an image, and 2 ) on the acasxu dataset. on a higher dimensional space like images, trace partitioning would take o ( npixels ) time, where n is the number of partitions per dimension. 3. 2 reluplex the l1 norm constraint on the entire image takes too long to run on reluplex. hence, we could only try the experiment on few images. we conduct 3 experiments for these few images : ( i ) perturb small regions only, giving explicit constraints for these regions. note that these perturbations are not a subset of l∞ if the norms are increased to the maximum change possible for each pixel. ( ii ) perturb small regions using the auxilliary networks instead. ( iii ) perturb entire image. we can further consider 3 types of norms in each experiment, namely, l∞, l1 and clipped norms given by lc = min ( l∞, l1 ), where l∞ ≤ δ, l1 ≤ [UNK], and [UNK] > δ. the benefit of lc can be seen by considering large l∞ and l1 norms as our search spaces : any l1 > 1 is not valid for images who ’ s values lie between 0 and 1, and large l∞ bounds cross the decision boundaries easily. the clipped norm manages to avoid both these issues. table 1 shows the robustness of our sparse network on different lc norms. since perturbing different regions using explicit constraints is limited to 3x4 pixels, the reluplex gives un - sat almost all the time. we run experiments ( i ) and ( ii ) for 173 regions. ( i ) was run with maximum l∞ bounds ( = 1 ) and no l1 restrictions and it gave un', 'metadata': {'source': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'file_path': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'page': 2, 'total_pages': 4, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.23', 'creationDate': 'D:20230425114654Z', 'modDate': 'D:20230425114654Z', 'trapped': ''}}, page_content='space with deeppoly but found that the option for trace partitioning only exists for two specific cases : 1 ) geometric transformation on an image, and 2 ) on the acasxu dataset. on a higher dimensional space like images, trace partitioning would take o ( npixels ) time, where n is the number of partitions per dimension. 3. 2 reluplex the l1 norm constraint on the entire image takes too long to run on reluplex. hence, we could only try the experiment on few images. we conduct 3 experiments for these few images : ( i ) perturb small regions only, giving explicit constraints for these regions. note that these perturbations are not a subset of l∞ if the norms are increased to the maximum change possible for each pixel. ( ii ) perturb small regions using the auxilliary networks instead. ( iii ) perturb entire image. we can further consider 3 types of norms in each experiment, namely, l∞, l1 and clipped norms given by lc = min ( l∞, l1 ), where l∞ ≤ δ, l1 ≤ [UNK], and [UNK] > δ. the benefit of lc can be seen by considering large l∞ and l1 norms as our search spaces : any l1 > 1 is not valid for images who ’ s values lie between 0 and 1, and large l∞ bounds cross the decision boundaries easily. the clipped norm manages to avoid both these issues. table 1 shows the robustness of our sparse network on different lc norms. since perturbing different regions using explicit constraints is limited to 3x4 pixels, the reluplex gives un - sat almost all the time. we run experiments ( i ) and ( ii ) for 173 regions. ( i ) was run with maximum l∞ bounds ( = 1 ) and no l1 restrictions and it gave un', metadata={'source': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'file_path': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'page': 2, 'total_pages': 4, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.23', 'creationDate': 'D:20230425114654Z', 'modDate': 'D:20230425114654Z', 'trapped': ''}), Document(lc_kwargs={'page_content': 'the reluplex gives un - sat almost all the time. we run experiments ( i ) and ( ii ) for 173 regions. ( i ) was run with maximum l∞ bounds ( = 1 ) and no l1 restrictions and it gave unsat for all values. ( ii ) was run on a bigger region ( 16x16 ) 3', 'metadata': {'source': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'file_path': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'page': 2, 'total_pages': 4, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.23', 'creationDate': 'D:20230425114654Z', 'modDate': 'D:20230425114654Z', 'trapped': ''}}, page_content='the reluplex gives un - sat almost all the time. we run experiments ( i ) and ( ii ) for 173 regions. ( i ) was run with maximum l∞ bounds ( = 1 ) and no l1 restrictions and it gave unsat for all values. ( ii ) was run on a bigger region ( 16x16 ) 3', metadata={'source': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'file_path': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'page': 2, 'total_pages': 4, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.23', 'creationDate': 'D:20230425114654Z', 'modDate': 'D:20230425114654Z', 'trapped': ''}), Document(lc_kwargs={'page_content': 'figure 3 : adversaries obtained by strongly perturbing regions. note that the image seems to have a large difference with the original one as the figure is displayed after normalising the perturbed image. once with maximum possible perturbations ( figure 3 shows the obtained adversaries ), and with l1 norm constrained to 1 ( 113 / 176 were verified correctly in this case ). the adversaries examples are skipped here for conciseness, but can be obtained by running our code ( see section 5 ) on default settings. 4 conclusion through our experiments, we conclude that l1 norm constraint verification on deeppoly is not possible using an auxiliary network because of the way the abstractions are constructed. there is a need for a general purpose way to trace partition the input like deeppoly does on the geometric transformations. with reluplex, the verification is infeasible when the entire image is allowed to perturb. reluplex can only handle the constraints on a small region of the image. therefore, we note that the current robustness analyzers are not capable of handling l1 perturbations. references [ 1 ] g. katz, c. barrett, d. l. dill, k. julian, and m. j. kochenderfer. reluplex : an efficient smt solver for verifying deep neural networks. in computer aided verification, pages 97 – 117. springer international publishing, 2017. doi : 10. 1007 / 978 - 3 - 319 - 63387 - 9 5. url https : / / doi. org / 10. 1007 % 2f978 - 3 - 319 - 63387 - 9 _ 5. [ 2 ] m. sharif, s. bhagavatula, l. bauer, and m. k. reiter. adversarial generative', 'metadata': {'source': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'file_path': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'page': 3, 'total_pages': 4, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.23', 'creationDate': 'D:20230425114654Z', 'modDate': 'D:20230425114654Z', 'trapped': ''}}, page_content='figure 3 : adversaries obtained by strongly perturbing regions. note that the image seems to have a large difference with the original one as the figure is displayed after normalising the perturbed image. once with maximum possible perturbations ( figure 3 shows the obtained adversaries ), and with l1 norm constrained to 1 ( 113 / 176 were verified correctly in this case ). the adversaries examples are skipped here for conciseness, but can be obtained by running our code ( see section 5 ) on default settings. 4 conclusion through our experiments, we conclude that l1 norm constraint verification on deeppoly is not possible using an auxiliary network because of the way the abstractions are constructed. there is a need for a general purpose way to trace partition the input like deeppoly does on the geometric transformations. with reluplex, the verification is infeasible when the entire image is allowed to perturb. reluplex can only handle the constraints on a small region of the image. therefore, we note that the current robustness analyzers are not capable of handling l1 perturbations. references [ 1 ] g. katz, c. barrett, d. l. dill, k. julian, and m. j. kochenderfer. reluplex : an efficient smt solver for verifying deep neural networks. in computer aided verification, pages 97 – 117. springer international publishing, 2017. doi : 10. 1007 / 978 - 3 - 319 - 63387 - 9 5. url https : / / doi. org / 10. 1007 % 2f978 - 3 - 319 - 63387 - 9 _ 5. [ 2 ] m. sharif, s. bhagavatula, l. bauer, and m. k. reiter. adversarial generative', metadata={'source': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'file_path': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'page': 3, 'total_pages': 4, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.23', 'creationDate': 'D:20230425114654Z', 'modDate': 'D:20230425114654Z', 'trapped': ''}), Document(lc_kwargs={'page_content': '##f978 - 3 - 319 - 63387 - 9 _ 5. [ 2 ] m. sharif, s. bhagavatula, l. bauer, and m. k. reiter. adversarial generative nets : neural network attacks on state - of - the - art face recognition. arxiv preprint 1801. 00349, dec. 2017. url https : / / arxiv. org / abs / 1801. 00349. [ 3 ] g. singh, t. gehr, m. p¨uschel, and m. vechev. an abstract domain for certifying neural networks. proc. acm program. lang., 3 ( popl ), jan 2019. doi : 10. 1145 / 3290354. url https : / / doi. org / 10. 1145 / 3290354. 5 links to implementation reluplex : https : / / github. com / cybershiptrooper / marabou deeppoly https : / / github. com / taufeeque9 / eranl1 4', 'metadata': {'source': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'file_path': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'page': 3, 'total_pages': 4, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.23', 'creationDate': 'D:20230425114654Z', 'modDate': 'D:20230425114654Z', 'trapped': ''}}, page_content='##f978 - 3 - 319 - 63387 - 9 _ 5. [ 2 ] m. sharif, s. bhagavatula, l. bauer, and m. k. reiter. adversarial generative nets : neural network attacks on state - of - the - art face recognition. arxiv preprint 1801. 00349, dec. 2017. url https : / / arxiv. org / abs / 1801. 00349. [ 3 ] g. singh, t. gehr, m. p¨uschel, and m. vechev. an abstract domain for certifying neural networks. proc. acm program. lang., 3 ( popl ), jan 2019. doi : 10. 1145 / 3290354. url https : / / doi. org / 10. 1145 / 3290354. 5 links to implementation reluplex : https : / / github. com / cybershiptrooper / marabou deeppoly https : / / github. com / taufeeque9 / eranl1 4', metadata={'source': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'file_path': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'page': 3, 'total_pages': 4, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.23', 'creationDate': 'D:20230425114654Z', 'modDate': 'D:20230425114654Z', 'trapped': ''})] titles=[Document(lc_kwargs={'page_content': 'CS 781 Project Report\\nVerifying L1 Adverserial Robustness\\nRohan Gupta\\n180010048@iitb.ac.in\\nMohammad Taufeeque\\n180050062@iitb.ac.in\\nAbstract.\\nWe study the performance of popular neural network verification tools\\non L1 perturbations.\\nSince feeding L1 constraints to solver is exponential in the\\norder of inputs, we experiment with function approximators to possibly reduce the\\ncomplexity.\\nWe give our results on two tools, Marabou (Reluplex) and ERAN\\n(DeepPoly) respectively.\\nKeywords: Verification of Neural Nets · L1 attack\\n1\\nIntroduction\\nMost verification tools show strong experimental results only for L∞ perturbations. However, attacks under\\nother Lp norms are becoming increasingly popular. It has also been observed that models robust to L∞ are\\nvulnerable to even small, perceptually minor departures from this family, such as small rotations and trans-\\nlations. Therefore, there is a need to look for high performance under other perturbations. The main issue\\nwith L∞ perturbations lies in making the bounds larger. Since the pixel-wise perturbations are independent,\\nit can easily cross the decision boundaries. [2] is an example of such adversaries, whose L∞ norm is large,\\nbut other Lp norms are not.\\nWe evaluate the performance of extant tools on L1 perturbations, with some modifications: instead of giving\\nexponential number of equations to the solver, an auxilliary network is used to find the L1 norm(conditions\\nare then applied to this output). We also observe some key differences between L1 and L∞ perturbations\\nvia our experiments. We show:\\n• Over approximations of DeepPoly [3] result in poor performance in the case of L1 norms, and in our\\nformulation, approximates it to it’s minimal L∞ super-set space.\\n• Strong L∞ perturbations limited to only a small region often leads to misclassification.\\n• A way to reduce large L∞ perturbation regions so that it does not tip over the decision boundaries\\nand a way to reduce spurious counterexamples for high L1 norms.\\n2\\nImplementation Details\\n2.1\\nAbstraction based solver (DeepPoly)\\nDeepPoly uses an over-approximation by choosing only two bounding lines to represent the abstraction. If L1\\nnorm constraints were enforced on the input, the exact approximation would require an exponential number\\nof constraints. The over approximation is very bad in this case. Figure 1 show the over approximation for\\na 2-pixel toy example. We therefore use an independent MLP network to output the L1 norm and apply\\nthe needed constraints inside it. The L∞ bounds for the input can then be chosen to be a super set of our\\noriginal L1 constraints. Figure 2 shows a network calculating the L1 norm for a single pixel. We can extend\\n1\\n', 'metadata': {'source': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'file_path': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'page': 0, 'total_pages': 4, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.23', 'creationDate': 'D:20230425114654Z', 'modDate': 'D:20230425114654Z', 'trapped': ''}}, page_content='CS 781 Project Report\\nVerifying L1 Adverserial Robustness\\nRohan Gupta\\n180010048@iitb.ac.in\\nMohammad Taufeeque\\n180050062@iitb.ac.in\\nAbstract.\\nWe study the performance of popular neural network verification tools\\non L1 perturbations.\\nSince feeding L1 constraints to solver is exponential in the\\norder of inputs, we experiment with function approximators to possibly reduce the\\ncomplexity.\\nWe give our results on two tools, Marabou (Reluplex) and ERAN\\n(DeepPoly) respectively.\\nKeywords: Verification of Neural Nets · L1 attack\\n1\\nIntroduction\\nMost verification tools show strong experimental results only for L∞ perturbations. However, attacks under\\nother Lp norms are becoming increasingly popular. It has also been observed that models robust to L∞ are\\nvulnerable to even small, perceptually minor departures from this family, such as small rotations and trans-\\nlations. Therefore, there is a need to look for high performance under other perturbations. The main issue\\nwith L∞ perturbations lies in making the bounds larger. Since the pixel-wise perturbations are independent,\\nit can easily cross the decision boundaries. [2] is an example of such adversaries, whose L∞ norm is large,\\nbut other Lp norms are not.\\nWe evaluate the performance of extant tools on L1 perturbations, with some modifications: instead of giving\\nexponential number of equations to the solver, an auxilliary network is used to find the L1 norm(conditions\\nare then applied to this output). We also observe some key differences between L1 and L∞ perturbations\\nvia our experiments. We show:\\n• Over approximations of DeepPoly [3] result in poor performance in the case of L1 norms, and in our\\nformulation, approximates it to it’s minimal L∞ super-set space.\\n• Strong L∞ perturbations limited to only a small region often leads to misclassification.\\n• A way to reduce large L∞ perturbation regions so that it does not tip over the decision boundaries\\nand a way to reduce spurious counterexamples for high L1 norms.\\n2\\nImplementation Details\\n2.1\\nAbstraction based solver (DeepPoly)\\nDeepPoly uses an over-approximation by choosing only two bounding lines to represent the abstraction. If L1\\nnorm constraints were enforced on the input, the exact approximation would require an exponential number\\nof constraints. The over approximation is very bad in this case. Figure 1 show the over approximation for\\na 2-pixel toy example. We therefore use an independent MLP network to output the L1 norm and apply\\nthe needed constraints inside it. The L∞ bounds for the input can then be chosen to be a super set of our\\noriginal L1 constraints. Figure 2 shows a network calculating the L1 norm for a single pixel. We can extend\\n1\\n', metadata={'source': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'file_path': '/Users/rohangupta/work/web_api_server/storage/test_pdfs/CS_781_Project.pdf', 'page': 0, 'total_pages': 4, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'creator': 'LaTeX with hyperref', 'producer': 'pdfTeX-1.40.23', 'creationDate': 'D:20230425114654Z', 'modDate': 'D:20230425114654Z', 'trapped': ''})] max_search_len=9\n"
     ]
    }
   ],
   "source": [
    "db_tool = DatabaseTool([os.path.join(dir, \"storage/test_pdfs/CS_781_Project.pdf\")])\n",
    "print(db_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain import HuggingFacePipeline, PromptTemplate, LLMChain\n",
    "from langchain.llms import OpenAI, AzureOpenAI\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils.chain_utils import *\n",
    "# abs path of ../\n",
    "dir = os.path.abspath(\"../\")\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"b11e8b01c8b44b9db9482f8cd7b410d4\"\n",
    "os.environ[\"OPENAI_API_VERSION\"]=\"2023-03-15-preview\"\n",
    "\n",
    "# https://gpt-jinshi.openai.azure.com/openai/deployments/GPT4/chat/completions?api-version=2023-03-15-preview'\n",
    "llm = AzureOpenAI( \n",
    "    openai_api_base=\"https://gpt-jinshi.openai.azure.com\",\n",
    "    deployment_name=\"GPT4/chat\",\n",
    "    max_tokens=3450, \n",
    "    max_retries=1,\n",
    "    temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url:  /openai/deployments/GPT4/chat/completions?api-version=2023-03-15-preview\n",
      "abs_url:  https://gpt-jinshi.openai.azure.com/openai/deployments/GPT4/chat/completions?api-version=2023-03-15-preview\n",
      "idk where url:  /openai/deployments/GPT4/chat/completions?api-version=2023-03-15-preview\n"
     ]
    },
    {
     "ename": "APIError",
     "evalue": "Invalid response object from API: 'Unsupported data type\\n' (HTTP response code was 400)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai_hackweek/lib/python3.9/site-packages/openai/api_requestor.py:405\u001b[0m, in \u001b[0;36mAPIRequestor.handle_error_response\u001b[0;34m(self, rbody, rcode, resp, rheaders, stream_error)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 405\u001b[0m     error_data \u001b[39m=\u001b[39m resp[\u001b[39m\"\u001b[39;49m\u001b[39merror\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m    406\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m llm\u001b[39m.\u001b[39;49mgenerate([\u001b[39m\"\u001b[39;49m\u001b[39mThis is a test prompt. Print hello world.\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai_hackweek/lib/python3.9/site-packages/langchain/llms/base.py:203\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m     run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[0;32m--> 203\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    204\u001b[0m run_manager\u001b[39m.\u001b[39mon_llm_end(output)\n\u001b[1;32m    205\u001b[0m \u001b[39mif\u001b[39;00m run_manager:\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai_hackweek/lib/python3.9/site-packages/langchain/llms/base.py:195\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_llm_start(\n\u001b[1;32m    191\u001b[0m     dumpd(\u001b[39mself\u001b[39m), prompts, invocation_params\u001b[39m=\u001b[39mparams, options\u001b[39m=\u001b[39moptions\n\u001b[1;32m    192\u001b[0m )\n\u001b[1;32m    193\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    194\u001b[0m     output \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 195\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_generate(\n\u001b[1;32m    196\u001b[0m             prompts, stop\u001b[39m=\u001b[39;49mstop, run_manager\u001b[39m=\u001b[39;49mrun_manager, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    197\u001b[0m         )\n\u001b[1;32m    198\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    199\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(prompts, stop\u001b[39m=\u001b[39mstop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m     run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai_hackweek/lib/python3.9/site-packages/langchain/llms/openai.py:327\u001b[0m, in \u001b[0;36mBaseOpenAI._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m     choices\u001b[39m.\u001b[39mextend(response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    326\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m     response \u001b[39m=\u001b[39m completion_with_retry(\u001b[39mself\u001b[39;49m, prompt\u001b[39m=\u001b[39;49m_prompts, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    328\u001b[0m     choices\u001b[39m.\u001b[39mextend(response[\u001b[39m\"\u001b[39m\u001b[39mchoices\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m    329\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstreaming:\n\u001b[1;32m    330\u001b[0m     \u001b[39m# Can't update token usage if streaming\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai_hackweek/lib/python3.9/site-packages/langchain/llms/openai.py:106\u001b[0m, in \u001b[0;36mcompletion_with_retry\u001b[0;34m(llm, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    104\u001b[0m     \u001b[39mreturn\u001b[39;00m llm\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 106\u001b[0m \u001b[39mreturn\u001b[39;00m _completion_with_retry(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai_hackweek/lib/python3.9/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai_hackweek/lib/python3.9/site-packages/tenacity/__init__.py:379\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m retry_state \u001b[39m=\u001b[39m RetryCallState(retry_object\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, fn\u001b[39m=\u001b[39mfn, args\u001b[39m=\u001b[39margs, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m    378\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m     do \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49miter(retry_state\u001b[39m=\u001b[39;49mretry_state)\n\u001b[1;32m    380\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai_hackweek/lib/python3.9/site-packages/tenacity/__init__.py:325\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    323\u001b[0m     retry_exc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mretry_error_cls(fut)\n\u001b[1;32m    324\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreraise:\n\u001b[0;32m--> 325\u001b[0m         \u001b[39mraise\u001b[39;00m retry_exc\u001b[39m.\u001b[39;49mreraise()\n\u001b[1;32m    326\u001b[0m     \u001b[39mraise\u001b[39;00m retry_exc \u001b[39mfrom\u001b[39;00m \u001b[39mfut\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexception\u001b[39;00m()\n\u001b[1;32m    328\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwait:\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai_hackweek/lib/python3.9/site-packages/tenacity/__init__.py:158\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreraise\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mNoReturn:\n\u001b[1;32m    157\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_attempt\u001b[39m.\u001b[39mfailed:\n\u001b[0;32m--> 158\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlast_attempt\u001b[39m.\u001b[39;49mresult()\n\u001b[1;32m    159\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai_hackweek/lib/python3.9/concurrent/futures/_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    438\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[0;32m--> 439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[1;32m    441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[1;32m    443\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai_hackweek/lib/python3.9/concurrent/futures/_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[1;32m    390\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 391\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[1;32m    392\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    393\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    394\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai_hackweek/lib/python3.9/site-packages/tenacity/__init__.py:382\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    381\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 382\u001b[0m         result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    383\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m:  \u001b[39m# noqa: B902\u001b[39;00m\n\u001b[1;32m    384\u001b[0m         retry_state\u001b[39m.\u001b[39mset_exception(sys\u001b[39m.\u001b[39mexc_info())  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai_hackweek/lib/python3.9/site-packages/langchain/llms/openai.py:104\u001b[0m, in \u001b[0;36mcompletion_with_retry.<locals>._completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 104\u001b[0m     \u001b[39mreturn\u001b[39;00m llm\u001b[39m.\u001b[39;49mclient\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai_hackweek/lib/python3.9/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai_hackweek/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py:156\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    131\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    132\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    140\u001b[0m ):\n\u001b[1;32m    141\u001b[0m     (\n\u001b[1;32m    142\u001b[0m         deployment_id,\n\u001b[1;32m    143\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    154\u001b[0m     )\n\u001b[0;32m--> 156\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    157\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    158\u001b[0m         url,\n\u001b[1;32m    159\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    160\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    161\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    162\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    163\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    164\u001b[0m     )\n\u001b[1;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    167\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    168\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai_hackweek/lib/python3.9/site-packages/openai/api_requestor.py:300\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39midk where url: \u001b[39m\u001b[39m\"\u001b[39m, url)\n\u001b[1;32m    299\u001b[0m \u001b[39m# raise \"Stoppo\"\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    301\u001b[0m \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai_hackweek/lib/python3.9/site-packages/openai/api_requestor.py:703\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    695\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    696\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    697\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m         )\n\u001b[1;32m    699\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    700\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    701\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    702\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 703\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    704\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    705\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    706\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    707\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    708\u001b[0m         ),\n\u001b[1;32m    709\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    710\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai_hackweek/lib/python3.9/site-packages/openai/api_requestor.py:766\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    764\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    765\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 766\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_error_response(\n\u001b[1;32m    767\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39;49mdata, rheaders, stream_error\u001b[39m=\u001b[39;49mstream_error\n\u001b[1;32m    768\u001b[0m     )\n\u001b[1;32m    769\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniconda3/envs/gen_ai_hackweek/lib/python3.9/site-packages/openai/api_requestor.py:407\u001b[0m, in \u001b[0;36mAPIRequestor.handle_error_response\u001b[0;34m(self, rbody, rcode, resp, rheaders, stream_error)\u001b[0m\n\u001b[1;32m    405\u001b[0m     error_data \u001b[39m=\u001b[39m resp[\u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    406\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[0;32m--> 407\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mAPIError(\n\u001b[1;32m    408\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mInvalid response object from API: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m (HTTP response code \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    409\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwas \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (rbody, rcode),\n\u001b[1;32m    410\u001b[0m         rbody,\n\u001b[1;32m    411\u001b[0m         rcode,\n\u001b[1;32m    412\u001b[0m         resp,\n\u001b[1;32m    413\u001b[0m     )\n\u001b[1;32m    415\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39minternal_message\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m error_data:\n\u001b[1;32m    416\u001b[0m     error_data[\u001b[39m\"\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m error_data[\u001b[39m\"\u001b[39m\u001b[39minternal_message\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[0;31mAPIError\u001b[0m: Invalid response object from API: 'Unsupported data type\\n' (HTTP response code was 400)"
     ]
    }
   ],
   "source": [
    "llm.generate([\"This is a test prompt. Print hello world.\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AzureOpenAI(lc_kwargs={'openai_api_base': 'https://gpt-jinshi.openai.azure.com/openai/deployments/', 'deployment_name': 'chat', 'model_name': 'GPT4', 'max_tokens': 3450, 'temperature': 0.0}, cache=None, verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.completion.Completion'>, model_name='GPT4', temperature=0.0, max_tokens=3450, top_p=1, frequency_penalty=0, presence_penalty=0, n=1, best_of=1, model_kwargs={}, openai_api_key='b11e8b01c8b44b9db9482f8cd7b410d4', openai_api_base='https://gpt-jinshi.openai.azure.com/openai/deployments/', openai_organization='', openai_proxy='', batch_size=20, request_timeout=None, logit_bias={}, max_retries=6, streaming=False, allowed_special=set(), disallowed_special='all', deployment_name='chat', openai_api_type='azure', openai_api_version='2023-03-15-preview')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' WE aceiwornva hello vaopr world '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts = \"\"\" WE aceiwornva {context} vaopr {prompt} \"\"\"\n",
    "prompts.format(context=\"hello\", prompt=\"world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen_ai_hackweek",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
